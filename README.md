# Data Processing Pipeline\n\nThis repository hosts a robust data processing pipeline, demonstrating how to transform raw data, ensure code quality, and automate deployment using Python, Pandas, Ruff, and GitHub Actions.\n\n## Project Overview\n\nThe core of this project involves processing data from an Excel file (`data.xlsx`), converting it to a CSV format (`data.csv`), performing data aggregation using a Python script (`execute.py`), and then publishing the processed results (`result.json`) via GitHub Pages.\n\nKey features include:\n*   **Data Transformation**: Converting `.xlsx` to `.csv` and processing the `.csv` with Pandas.\n*   **Code Quality**: Automated linting with `ruff`.\n*   **CI/CD Automation**: A GitHub Actions workflow (`.github/workflows/ci.yml`) that runs on every push.\n*   **Automated Deployment**: Processed `result.json` is automatically deployed to GitHub Pages.\n\n## Repository Contents\n\n*   `execute.py`: The Python script responsible for reading `data.csv`, performing data aggregation, and writing the output to `result.json`.\n*   `data.xlsx`: The original raw data file in Excel format.\n*   `data.csv`: The converted and committed CSV version of `data.xlsx`, used by `execute.py`.\n*   `.github/workflows/ci.yml`: The GitHub Actions workflow definition.\n*   `index.html`: A simple, responsive web page demonstrating the project and linking to the generated results.\n*   `README.md`: This file.\n*   `LICENSE`: The MIT License for this project.\n\n## Setup and Local Execution\n\nTo set up the project locally and run the data processing script:\n\n1.  **Prerequisites**:\n    *   Python 3.11+\n    *   `pip` (Python package installer)\n\n2.  **Ensure `data.csv` is present**:\n    The `data.xlsx` file has been converted to `data.csv` and committed to the repository. The `execute.py` script relies on `data.csv`.\n\n3.  **Create a virtual environment (recommended)**:\n    ```bash\n    python -m venv .venv\n    source .venv/bin/activate  # On Windows: .venv\Scripts\activate\n    ```\n\n4.  **Install dependencies**:\n    ```bash\n    pip install pandas ruff\n    ```\n\n5.  **Run the data processing script**:\n    ```bash\n    python execute.py\n    ```\n    This will generate a `result.json` file in your project root, containing the aggregated data.\n\n6.  **Run Ruff linter**:\n    ```bash\n    ruff check .\n    ```\n\n## GitHub Actions CI/CD Pipeline\n\nThe `.github/workflows/ci.yml` file defines a GitHub Actions workflow that automates the following steps on every push to the `main` branch:\n\n1.  **Checkout Code**: Retrieves the repository content.\n2.  **Setup Python**: Configures Python 3.11 environment.\n3.  **Install Dependencies**: Installs `pandas` and `ruff`.\n4.  **Run Ruff Linter**: Checks the Python code for style and common errors.\n5.  **Run `execute.py`**: Executes the data processing script, which generates `result.json`.\n6.  **Prepare for GitHub Pages**: Moves `result.json` into a `public/` directory.\n7.  **Deploy to GitHub Pages**: Publishes the contents of the `public/` directory (including `result.json`) to GitHub Pages.\n\nYou can view the CI/CD pipeline status and logs under the "Actions" tab in your GitHub repository.\n\n## Accessing Processed Results (GitHub Pages)\n\nThe `result.json` file generated by `execute.py` is automatically deployed to GitHub Pages.\nYou can access the generated JSON output at:\n`https://your-username.github.io/your-repo-name/result.json`\n\nReplace `your-username` and `your-repo-name` with your actual GitHub username and repository name.\n\n## License\n\nThis project is licensed under the MIT License - see the `LICENSE` file for details.\n